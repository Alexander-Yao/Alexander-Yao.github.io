<!DOCTYPE html
	PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>Controllable 3D Face Synthesis with Conditional Generative Occupancy Fields</title>

	<!-- Meta tags for search engines to crawl -->
	<meta name="robots" content="index,follow">
	<meta name="description"
		content="We propose a new NeRF-based conditional 3D face synthesis framework, which enables 3D controllability over the generated face images by imposing explicit 3D conditions from 3D face priors. At its core is a conditional Generative Occupancy Field (cGOF) that effectively enforces the shape of the generated face to commit to a given 3D Morphable Model (3DMM) mesh.">
	<meta name="keywords"
		content="cGOF; Generative Adversarial Network; Neural Radiance Field; Convolutional Neural Network; deep learning; computer vision;">
	<link rel="author" href="http://keqiangsun.github.io/">

	<!-- Fonts and stuff -->
	<link href="css" rel="stylesheet" type="text/css">
	<link rel="stylesheet" type="text/css" href="project.css" media="screen">
	<link rel="stylesheet" type="text/css" media="screen" href="iconize.css">
	<script async="" src="prettify.js"></script>

</head>


<body>
	<div id="content">
		<div id="content-inner">

			<div class="section head">
				<h1>
					<font size="5">Controllable 3D Face Synthesis with Conditional Generative Occupancy Fields</font>
				</h1>

				<div class="authors">
					<a href="http://keqiangsun.github.io/">Keqiang Sun</a><sup>1</sup>&nbsp;&nbsp;
					<a href="https://elliottwu.com">Shangzhe Wu</a><sup>2</sup>&nbsp;&nbsp;
					<a href="https://drinkingcoder.github.io">Zhaoyang Huang</a><sup>1</sup>&nbsp;&nbsp;
					<a>Ning Zhang</a><sup>3</sup>&nbsp;&nbsp;
					<a href="https://scholar.google.com/citations?user=KmxEHm4AAAAJ&hl=zh-TW&oi=ao">Quan
						Wang</a><sup>3</sup>&nbsp;&nbsp;
					<a href="https://www.ee.cuhk.edu.hk/~hsli/">HongSheng Li</a><sup>1</sup>&nbsp;&nbsp;
				</div>

				<div class="affiliations">
					<sup>1</sup><a href="http://mmlab.ie.cuhk.edu.hk">CUHK
						MMLab</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
					<sup>2</sup><a href="http://www.robots.ox.ac.uk/~vgg/">Oxford
						VGG</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
					<sup>3</sup><a href="https://www.sensetime.com/?lang=en-us">SenseTime Research</a>
				</div>

				<div class="section downloads">
					<!-- <h2>Downloads</h2> -->
					<center>
						<ul>
							<li class="grid">
								<div class="griditem">
									<a href="https://arxiv.org/abs/2206.08361" target="_blank" class="imageLink"><img
											src="paper.png" width="10%" ></a><br><a href="https://arxiv.org/abs/2206.08361">Paper and Appendix</a>
								</div>
							</li>
							<li class="grid">
								<div class="griditem">
									<img src="code.png" width="10%" ><br><a href="https://github.com/keqiangsun/cGOF"
										target="_blank">Code and Model</a>
								</div>
							</li>
						</ul>
					</center>
				</div>
	
			</div>


			<!-- <center><img src="teaser.mp4" width="60%" border="0"></center> -->

			<center>
				<!-- <iframe src="https://www.youtube.com/embed/XcLHH-YUFPY" allow="autoplay; encrypted-media"
					allowfullscreen="" width="560" height="315" frameborder="0"></iframe> -->
				<img src="video.mp4" width="80%" border="0">
			</center>
			<div class="section abstract">
				<h2>Abstract</h2>
				<p>
					Capitalizing on the recent advances in image generation models, existing controllable face image
					synthesis methods are able to generate high-fidelity images with some levels of controllability,
					e.g., controlling the shapes, expressions, textures, and poses of the generated face images.
					However, these methods focus on 2D image generative models, which are prone to producing
					inconsistent face images under large expression and pose changes.
					In this paper, we propose a new NeRF-based conditional 3D face synthesis framework, which enables 3D
					controllability over the generated face images by imposing explicit 3D conditions from 3D face
					priors.
					At its core is a conditional Generative Occupancy Field (cGOF) that effectively enforces the shape
					of the generated face to commit to a given 3D Morphable Model (3DMM) mesh.
					To achieve accurate control over fine-grained 3D face shapes of the synthesized image, we
					additionally incorporate a 3D landmark loss as well as a volume warping loss into our synthesis
					algorithm.
					Experiments validate the effectiveness of the proposed method, which is able to generate
					high-fidelity face images and shows more precise 3D controllability than state-of-the-art 2D-based
					controllable face synthesis methods.
				</p>
			</div>
			<div class="section method">
				<h2>Method Overview</h2>
				<center><img src="method.png" width="80%" border="0"></center>
				<p>
					(Top): Conditional Generative Occupancy Field (cGOF) leverages a mesh-guided volume sampler and a distance-aware volume density regularizer,
					which effectively conditions the generated NeRF on an input 3DMM mesh. It is trained in an adversarial learning framework using only single-view images.
					(Bottom): The 3D landmark loss encourages the semantically important facial landmarks to follow the input mesh,
					and the volume warping loss enforces two NeRF volumes generated with different expression codes to be consistent
					through a warping field induced from the corresponding 3DMM meshes
				</p>
			</div>
			<div class="section demo">
				<h2>Results</h2>

				<h3>Pose Control</h3>
				<center>
					<h4>Pose Control Result Comparison.</h4>
				</center>
				<center><img src="pose_cmp.png" width="100%" border="0"></center>
				<center>
					<h4>Our Pose Control Demo.</h4>
				</center>
				<center><img src="poses.mp4" width="80%" border="0"></center>
				

				<h3>Expression Control</h3>
				<center>
					<h4>Expression Control Results of DiscoFaceGan.</h4>
				</center>
				<center><img src="discofacegan_exp.pdf" width="80%" border="0"></center>

				<center>
					<h4>Expression Control Results of GAN-Control.</h4>
				</center>
				<center><img src="gan_control_exp.pdf" width="80%" border="0"></center>

				<center>
					<h4>Expression Control Results of Our Method.</h4>
				</center>
				<center><img src="cgof_exp_mild.pdf" width="80%" border="0"></center>
				<center><img src="cgof_exp_wild.pdf" width="80%" border="0"></center>

				<center>
					<font size="3">Our Expression Control Demo.</font>
				</center>
				<center><img src="mesh_exp_norm.mp4" width="80%" border="0"></center>
				
			</div>



			<br>
			<div class="section list">
				<h2>Citation</h2>

				<div class="section bibtex">
					<pre>
@misc{https://doi.org/10.48550/arxiv.2206.08361,
	doi = {10.48550/ARXIV.2206.08361},
	url = {https://arxiv.org/abs/2206.08361},
	author = {Sun, Keqiang and Wu, Shangzhe and Huang, Zhaoyang and Zhang, Ning and Wang, Quan and Li, HongSheng},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {Controllable 3D Face Synthesis with Conditional Generative Occupancy Fields},
	publisher = {arXiv},
	year = {2022},
	copyright = {arXiv.org perpetual, non-exclusive license}
	}
				  </pre>
				</div>
			</div>


	</div>
	</div>


</body>

</html>