<!DOCTYPE html
	PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>Controllable 3D Face Synthesis with Conditional Generative Occupancy Fields</title>

	<!-- Meta tags for search engines to crawl -->
	<meta name="robots" content="index,follow">
	<meta name="description"
		content="We propose a new NeRF-based conditional 3D face synthesis framework, which enables 3D controllability over the generated face images by imposing explicit 3D conditions from 3D face priors. At its core is a conditional Generative Occupancy Field (cGOF) that effectively enforces the shape of the generated face to commit to a given 3D Morphable Model (3DMM) mesh.">
	<meta name="keywords"
		content="cGOF; Generative Adversarial Network; Neural Radiance Field; Convolutional Neural Network; deep learning; computer vision;">
	<link rel="author" href="http://keqiangsun.github.io/">

	<!-- Fonts and stuff -->
	<link href="css" rel="stylesheet" type="text/css">
	<link rel="stylesheet" type="text/css" href="project.css" media="screen">
	<link rel="stylesheet" type="text/css" media="screen" href="iconize.css">
	<script async="" src="prettify.js"></script>

</head>


<body>
	<div id="content">
		<div id="content-inner">

			<div class="section head">
				<h1>
					<font size="5">Controllable 3D Face Synthesis with Conditional Generative Occupancy Fields</font>
				</h1>

				<div class="authors">
					<a href="http://keqiangsun.github.io/">Keqiang Sun</a><sup>1</sup>&nbsp;&nbsp;
					<a href="https://elliottwu.com">Shangzhe Wu</a><sup>2</sup>&nbsp;&nbsp;
					<a href="https://elliottwu.com">Zhaoyang Huang</a><sup>1</sup>&nbsp;&nbsp;
					<a href="">Ning Zhang</a><sup>3</sup>&nbsp;&nbsp;
					<a href="https://scholar.google.com/citations?user=KmxEHm4AAAAJ&hl=zh-TW&oi=ao">Quan
						Wang</a><sup>3</sup>&nbsp;&nbsp;
					<a href="https://www.ee.cuhk.edu.hk/~hsli/">HongSheng Li</a><sup>1</sup>&nbsp;&nbsp;
				</div>

				<div class="affiliations">
					<sup>1</sup><a href="http://mmlab.ie.cuhk.edu.hk">CUHK
						MMLab</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
					<sup>2</sup><a href="http://www.robots.ox.ac.uk/~vgg/">Oxford
						VGG</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
					<sup>3</sup><a href="https://www.sensetime.com/?lang=en-us">SenseTime Research</a>
				</div>

			</div>


			<center><img src="teaser.png" width="100%" border="0"></center>
			<div class="section abstract">
				<h2>Abstract</h2>
				<p>
					Capitalizing on the recent advances in image generation models, existing controllable face image
					synthesis methods are able to generate high-fidelity images with some levels of controllability,
					e.g., controlling the shapes, expressions, textures, and poses of the generated face images.
					However, these methods focus on 2D image generative models, which are prone to producing
					inconsistent face images under large expression and pose changes.
					In this paper, we propose a new NeRF-based conditional 3D face synthesis framework, which enables 3D
					controllability over the generated face images by imposing explicit 3D conditions from 3D face
					priors.
					At its core is a conditional Generative Occupancy Field (cGOF) that effectively enforces the shape
					of the generated face to commit to a given 3D Morphable Model (3DMM) mesh.
					To achieve accurate control over fine-grained 3D face shapes of the synthesized image, we
					additionally incorporate a 3D landmark loss as well as a volume warping loss into our synthesis
					algorithm.
					Experiments validate the effectiveness of the proposed method, which is able to generate
					high-fidelity face images and shows more precise 3D controllability than state-of-the-art 2D-based
					controllable face synthesis methods.
				</p>
			</div>
			<div class="section downloads">
				<h2>Demo</h2>
				<center>
					<iframe src="https://www.youtube.com/embed/XcLHH-YUFPY" allow="autoplay; encrypted-media"
						allowfullscreen="" width="560" height="315" frameborder="0"></iframe>
				</center>
			</div>
			<div class="section downloads">
				<h2>Downloads</h2>
				<center>
					<ul>
						<li class="grid">
							<div class="griditem">
								<a href="https://arxiv.org/abs/1805.10483" target="_blank" class="imageLink"><img
										src="paper.png"></a><br><a href="https://arxiv.org/abs/1805.10483">Paper</a>
							</div>
						</li>
						<li class="grid">
							<div class="griditem">
								<img src="code.png"><br><a href="https://github.com/keqiangsun/cGOF"
									target="_blank">Code
									and Model</a>
							</div>
						</li>
					</ul>
				</center>
			</div>



			<br>
			<div class="section list">
				<h2>Citation</h2>

				<div class="section bibtex">
					<pre>
@inproceedings{keqiang2019fab,
author = {Sun, Keqiang and Wu, Wayne and Liu, Tinghao and Yang, Shuo and Wang, Quan and Zhou, Qiang and and Ye, Zuochang and Qian, Chen},
title = {FAB: A Robust Facial Landmark Detection Framework for Motion-Blurred Videos},
booktitle = {ICCV},
month = October,
year = {2019}
}
				  </pre>
				</div>
			</div>


	</div>
	</div>


</body>

</html>